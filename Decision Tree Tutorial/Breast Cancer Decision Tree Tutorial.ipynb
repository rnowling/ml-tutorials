{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees and Random Forests\n",
    "\n",
    "[Decision Trees](http://scikit-learn.org/stable/modules/tree.html) are a model for classification that utilizes trees.  Each node in the decision tree applies an inequality to a particular feature, resulting in a boolean output.  For each of the two possible outputs, there is a child node.  The leaves of the tree representing classification decisions; the predicted labels for the leaf nodes come from determining what the most common label is among the samples at that leaf. \n",
    "\n",
    "The decision tree is trained through a greedy algorithm.  All combinations of features and thresholds are evaluated at each split.  The feature and threshold combination that optimizes the \"gini impurity\" is used for that node.  The goal is to divide the divide by class as quickly as possible.\n",
    "\n",
    "To classify a given sample, you start from the top of the tree.  At each node, you evaluate the inequality and move the sample down to the left (true) or right (false) child.  When you reach a leaf, you use the label associated with that leaf to classify the sample.\n",
    "\n",
    "Advantages of decision trees include:\n",
    "\n",
    "* Feature selection -- the decision tree can pick the fits it finds to be most useful\n",
    "* Interpretability -- decision trees can be easily interpreted to explain how samples are classified\n",
    "\n",
    "The downsides of decision trees include:\n",
    "\n",
    "* Unstable -- small changes in the training set can result in very different trees\n",
    "* Feature selection is good but not perfect\n",
    "* Not as accurate as other technique\n",
    "\n",
    "To illustrate the feature selection capabilities, we'll use our greedy method for choosing features and compare with training a decision tree on all of our features.  We'll then repeat this process using [Random Forests](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), a more advanced technique that builds on decision trees.\n",
    "\n",
    "For this tutorial, we will use the Wisconsin breast cancer data set.  We will classify tumors as benign or malignant based on their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Cell.shape</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Cl.thickness  Cell.size  Cell.shape  Marg.adhesion  Epith.c.size  \\\n",
       "0  1000025             5          1           1              1             2   \n",
       "1  1002945             5          4           4              5             7   \n",
       "2  1015425             3          1           1              1             2   \n",
       "3  1016277             6          8           8              1             3   \n",
       "4  1017023             4          1           1              3             2   \n",
       "\n",
       "   Bare.nuclei  Bl.cromatin  Normal.nucleoli  Mitoses   Class  \n",
       "0          1.0            3                1        1  benign  \n",
       "1         10.0            3                2        1  benign  \n",
       "2          2.0            3                1        1  benign  \n",
       "3          4.0            3                7        1  benign  \n",
       "4          1.0            3                1        1  benign  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                   int64\n",
       "Cl.thickness         int64\n",
       "Cell.size            int64\n",
       "Cell.shape           int64\n",
       "Marg.adhesion        int64\n",
       "Epith.c.size         int64\n",
       "Bare.nuclei        float64\n",
       "Bl.cromatin          int64\n",
       "Normal.nucleoli      int64\n",
       "Mitoses              int64\n",
       "Class               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's look at the distribution of the outcome variable `Class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign       458\n",
      "malignant    241\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Number of Samples')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = df[\"Class\"].value_counts()\n",
    "print(class_counts)\n",
    "class_counts.plot.bar()\n",
    "plt.ylabel(\"Number of Samples\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is imbalanced.  Meaning, we have twice as many benign samples as malignant samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699 524 175\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, stratify=df[\"Class\"])\n",
    "print(df.shape[0], df_train.shape[0], df_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our labels are given as a strings, which we then converted to a categorical variable.  Scikit-Learn classifiers expect that outcome variables are denoted by integers -- one integer per category.  We can use the `LabelEncoder` to transform the strings to integers and store an internal representation for easier conversation back later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0\n",
      " 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0\n",
      " 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0\n",
      " 0 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0\n",
      " 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1\n",
      " 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0\n",
      " 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(df_train[\"Class\"].astype(\"str\"))\n",
    "y_test = encoder.transform(df_test[\"Class\"].astype(\"str\"))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection with Greedy Algorithm\n",
    "\n",
    "The Wisconsin Breast Cancer data set features are all numerical, so we don't transform anything into dummy variables.  We just create some placeholder data structures so we can reuse our existing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_columns = df.columns[1:-1]\n",
    "dummy_columns = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrices(df_train, df_test, selected_columns, dummy_columns):\n",
    "    \"\"\"\n",
    "    Creates feature matrices for the training and testing sets from the given dataframes.\n",
    "    The feature matrices are built from the columns given in selected columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # keep track of numerical features\n",
    "    numerical_trial_columns = []\n",
    "    \n",
    "    # keep track of dummy features for categorical variables\n",
    "    categorical_trial_columns = []\n",
    "    \n",
    "    # build feature lists\n",
    "    for col_name in selected_columns:\n",
    "        if col_name in dummy_columns:\n",
    "            categorical_trial_columns.extend(dummy_columns[col_name])\n",
    "        else:\n",
    "            numerical_trial_columns.append(col_name)\n",
    "\n",
    "    # transform numerical features\n",
    "    if len(numerical_trial_columns) > 0:\n",
    "        X_train_numerical = df_train[numerical_trial_columns].astype(\"float64\").values\n",
    "        X_test_numerical = df_test[numerical_trial_columns].astype(\"float64\").values\n",
    "    \n",
    "        imputer = Imputer()\n",
    "        X_train_numerical = imputer.fit_transform(X_train_numerical)\n",
    "        X_test_numerical = imputer.transform(X_test_numerical)\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "        X_train_numerical = scaler.fit_transform(X_train_numerical)\n",
    "        X_test_numerical = scaler.transform(X_test_numerical)\n",
    "    \n",
    "    # select categorical features\n",
    "    if len(categorical_trial_columns) > 0:\n",
    "        X_train_categorical = df_train[categorical_trial_columns].astype(\"float64\").values\n",
    "        X_test_categorical = df_test[categorical_trial_columns].astype(\"float64\").values\n",
    "    \n",
    "    # concatenate feature matrices\n",
    "    if len(numerical_trial_columns) > 0 and len(categorical_trial_columns) > 0:\n",
    "        X_train = np.hstack([X_train_numerical, X_train_categorical])\n",
    "        X_test = np.hstack([X_test_numerical, X_test_categorical])\n",
    "    elif len(numerical_trial_columns) > 0:\n",
    "        X_train = X_train_numerical\n",
    "        X_test = X_test_numerical\n",
    "    else:\n",
    "        X_train = X_train_categorical\n",
    "        X_test = X_test_categorical\n",
    "        \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Model Accuracy: 0.0\n",
      "\n",
      "Cl.thickness Accuracy: 0.8628571428571429\n",
      "\n",
      "Cell.size Accuracy: 0.9257142857142857\n",
      "\n",
      "Cell.shape Accuracy: 0.92\n",
      "\n",
      "Marg.adhesion Accuracy: 0.8742857142857143\n",
      "\n",
      "Epith.c.size Accuracy: 0.8914285714285715\n",
      "\n",
      "Bare.nuclei Accuracy: 0.88\n",
      "\n",
      "Bl.cromatin Accuracy: 0.9028571428571428\n",
      "\n",
      "Normal.nucleoli Accuracy: 0.92\n",
      "\n",
      "Mitoses Accuracy: 0.8057142857142857\n",
      "\n",
      "Sorted columns:['Cell.size', 'Cell.shape', 'Normal.nucleoli', 'Bl.cromatin', 'Epith.c.size', 'Bare.nuclei', 'Marg.adhesion', 'Cl.thickness', 'Mitoses']\n"
     ]
    }
   ],
   "source": [
    "null_accuracy = 0.0\n",
    "print(\"Null Model Accuracy:\", null_accuracy)\n",
    "\n",
    "column_accuracies = []\n",
    "\n",
    "for col_name in candidate_columns:\n",
    "    X_train, X_test = create_feature_matrices(df_train,\n",
    "                                             df_test,\n",
    "                                             [col_name],\n",
    "                                             dummy_columns)\n",
    "    \n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train, y_train)\n",
    "    pred_labels = dt.predict(X_test)\n",
    "    pred_probs = dt.predict_proba(X_test)\n",
    "    simple_accuracy = accuracy_score(y_test, pred_labels)\n",
    "    print()\n",
    "    print(col_name + \" Accuracy:\", simple_accuracy)\n",
    "    column_accuracies.append((simple_accuracy, col_name))\n",
    "    \n",
    "column_accuracies.sort(key=lambda p: p[0], reverse=True)\n",
    "sorted_columns = [col_name for _, col_name in column_accuracies]\n",
    "print()\n",
    "print(\"Sorted columns:\" + str(sorted_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Accuracy: 0.0\n",
      "\n",
      "\n",
      "['Cell.size'] Model Accuracy: 0.9257142857142857\n",
      "Updating base model\n",
      "\n",
      "Base Model Accuracy: 0.9257142857142857\n",
      "\n",
      "\n",
      "['Cell.size', 'Cell.shape'] Model Accuracy: 0.92\n",
      "\n",
      "Base Model Accuracy: 0.9257142857142857\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli'] Model Accuracy: 0.9314285714285714\n",
      "Updating base model\n",
      "\n",
      "Base Model Accuracy: 0.9314285714285714\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin'] Model Accuracy: 0.9428571428571428\n",
      "Updating base model\n",
      "\n",
      "Base Model Accuracy: 0.9428571428571428\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Epith.c.size'] Model Accuracy: 0.92\n",
      "\n",
      "Base Model Accuracy: 0.9428571428571428\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Bare.nuclei'] Model Accuracy: 0.9257142857142857\n",
      "\n",
      "Base Model Accuracy: 0.9428571428571428\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Marg.adhesion'] Model Accuracy: 0.8971428571428571\n",
      "\n",
      "Base Model Accuracy: 0.9428571428571428\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Cl.thickness'] Model Accuracy: 0.9485714285714286\n",
      "Updating base model\n",
      "\n",
      "Base Model Accuracy: 0.9485714285714286\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Cl.thickness', 'Mitoses'] Model Accuracy: 0.9542857142857143\n",
      "Updating base model\n",
      "\n",
      "Base Model Accuracy: 0.9542857142857143\n",
      "\n",
      "Our chosen columns are: ['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Cl.thickness', 'Mitoses']\n"
     ]
    }
   ],
   "source": [
    "base_model_columns = []\n",
    "base_accuracy = null_accuracy\n",
    "\n",
    "print(\"Base Model Accuracy:\", base_accuracy)\n",
    "print()\n",
    "\n",
    "for col_name in sorted_columns:\n",
    "    # track all column names\n",
    "    trial_columns = base_model_columns[:]\n",
    "    trial_columns.append(col_name)\n",
    "\n",
    "    X_train, X_test = create_feature_matrices(df_train,\n",
    "                                             df_test,\n",
    "                                             trial_columns,\n",
    "                                             dummy_columns)\n",
    "    \n",
    "    trial_dt = DecisionTreeClassifier()\n",
    "    trial_dt.fit(X_train, y_train)\n",
    "    pred_labels = trial_dt.predict(X_test)\n",
    "    trial_accuracy = accuracy_score(y_test, pred_labels)\n",
    "    print()\n",
    "    print(str(trial_columns) + \" Model Accuracy:\", trial_accuracy)\n",
    "\n",
    "    if trial_accuracy > base_accuracy:\n",
    "        print(\"Updating base model\")\n",
    "        base_model_columns = trial_columns\n",
    "        base_accuracy = trial_accuracy\n",
    "    print()\n",
    "    print(\"Base Model Accuracy:\", base_accuracy)\n",
    "    print()\n",
    "    \n",
    "print(\"Our chosen columns are: \" + str(base_model_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try putting all of our features into a Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 0.9542857142857143\n",
      "Labels: ['benign' 'malignant']\n",
      "Confusion matrix:\n",
      "[[114   1]\n",
      " [  7  53]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = create_feature_matrices(df_train,\n",
    "                                          df_test,\n",
    "                                          sorted_columns,\n",
    "                                          dummy_columns)\n",
    "    \n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "pred_labels = dt.predict(X_test)\n",
    "trial_accuracy = accuracy_score(y_test, pred_labels)\n",
    "cm = confusion_matrix(y_test, pred_labels)\n",
    "print()\n",
    "print(\"Model Accuracy:\", trial_accuracy)\n",
    "print(\"Labels:\", encoder.classes_)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our greedy process for evaluating features achieved an accuracy of 95%, which is on par with the Decision Tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "We are now going to try the more sophisticated Random Forests method.  We will go through the greedy process as well as trying to throw all of the features into a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Model Accuracy: 0.0\n",
      "\n",
      "Cl.thickness Accuracy: 0.8628571428571429\n",
      "\n",
      "Cell.size Accuracy: 0.9257142857142857\n",
      "\n",
      "Cell.shape Accuracy: 0.92\n",
      "\n",
      "Marg.adhesion Accuracy: 0.8514285714285714\n",
      "\n",
      "Epith.c.size Accuracy: 0.8914285714285715\n",
      "\n",
      "Bare.nuclei Accuracy: 0.88\n",
      "\n",
      "Bl.cromatin Accuracy: 0.9028571428571428\n",
      "\n",
      "Normal.nucleoli Accuracy: 0.92\n",
      "\n",
      "Mitoses Accuracy: 0.8057142857142857\n",
      "\n",
      "Sorted columns:['Cell.size', 'Cell.shape', 'Normal.nucleoli', 'Bl.cromatin', 'Epith.c.size', 'Bare.nuclei', 'Cl.thickness', 'Marg.adhesion', 'Mitoses']\n"
     ]
    }
   ],
   "source": [
    "null_accuracy = 0.0\n",
    "print(\"Null Model Accuracy:\", null_accuracy)\n",
    "\n",
    "column_accuracies = []\n",
    "\n",
    "for col_name in candidate_columns:\n",
    "    X_train, X_test = create_feature_matrices(df_train,\n",
    "                                             df_test,\n",
    "                                             [col_name],\n",
    "                                             dummy_columns)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_labels = rf.predict(X_test)\n",
    "    pred_probs = rf.predict_proba(X_test)\n",
    "    simple_accuracy = accuracy_score(y_test, pred_labels)\n",
    "    print()\n",
    "    print(col_name + \" Accuracy:\", simple_accuracy)\n",
    "    column_accuracies.append((simple_accuracy, col_name))\n",
    "    \n",
    "column_accuracies.sort(key=lambda p: p[0], reverse=True)\n",
    "sorted_columns = [col_name for _, col_name in column_accuracies]\n",
    "print()\n",
    "print(\"Sorted columns:\" + str(sorted_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Accuracy: 0.0\n",
      "\n",
      "\n",
      "['Cell.size'] Model Accuracy: 0.9257142857142857\n",
      "Updating base model\n",
      "\n",
      "Base Model Accuracy: 0.9257142857142857\n",
      "\n",
      "\n",
      "['Cell.size', 'Cell.shape'] Model Accuracy: 0.9257142857142857\n",
      "\n",
      "Base Model Accuracy: 0.9257142857142857\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli'] Model Accuracy: 0.9428571428571428\n",
      "Updating base model\n",
      "\n",
      "Base Model Accuracy: 0.9428571428571428\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin'] Model Accuracy: 0.96\n",
      "Updating base model\n",
      "\n",
      "Base Model Accuracy: 0.96\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Epith.c.size'] Model Accuracy: 0.9542857142857143\n",
      "\n",
      "Base Model Accuracy: 0.96\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Bare.nuclei'] Model Accuracy: 0.9542857142857143\n",
      "\n",
      "Base Model Accuracy: 0.96\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Cl.thickness'] Model Accuracy: 0.9542857142857143\n",
      "\n",
      "Base Model Accuracy: 0.96\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Marg.adhesion'] Model Accuracy: 0.9485714285714286\n",
      "\n",
      "Base Model Accuracy: 0.96\n",
      "\n",
      "\n",
      "['Cell.size', 'Normal.nucleoli', 'Bl.cromatin', 'Mitoses'] Model Accuracy: 0.9542857142857143\n",
      "\n",
      "Base Model Accuracy: 0.96\n",
      "\n",
      "Our chosen columns are: ['Cell.size', 'Normal.nucleoli', 'Bl.cromatin']\n"
     ]
    }
   ],
   "source": [
    "base_model_columns = []\n",
    "base_accuracy = null_accuracy\n",
    "\n",
    "print(\"Base Model Accuracy:\", base_accuracy)\n",
    "print()\n",
    "\n",
    "for col_name in sorted_columns:\n",
    "    # track all column names\n",
    "    trial_columns = base_model_columns[:]\n",
    "    trial_columns.append(col_name)\n",
    "\n",
    "    X_train, X_test = create_feature_matrices(df_train,\n",
    "                                             df_test,\n",
    "                                             trial_columns,\n",
    "                                             dummy_columns)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_labels = rf.predict(X_test)\n",
    "    trial_accuracy = accuracy_score(y_test, pred_labels)\n",
    "    print()\n",
    "    print(str(trial_columns) + \" Model Accuracy:\", trial_accuracy)\n",
    "\n",
    "    if trial_accuracy > base_accuracy:\n",
    "        print(\"Updating base model\")\n",
    "        base_model_columns = trial_columns\n",
    "        base_accuracy = trial_accuracy\n",
    "    print()\n",
    "    print(\"Base Model Accuracy:\", base_accuracy)\n",
    "    print()\n",
    "    \n",
    "print(\"Our chosen columns are: \" + str(base_model_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 0.9714285714285714\n",
      "Labels: ['benign' 'malignant']\n",
      "Confusion matrix:\n",
      "[[114   1]\n",
      " [  4  56]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = create_feature_matrices(df_train,\n",
    "                                          df_test,\n",
    "                                          sorted_columns,\n",
    "                                          dummy_columns)\n",
    "    \n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_labels = rf.predict(X_test)\n",
    "trial_accuracy = accuracy_score(y_test, pred_labels)\n",
    "cm = confusion_matrix(y_test, pred_labels)\n",
    "print()\n",
    "print(\"Model Accuracy:\", trial_accuracy)\n",
    "print(\"Labels:\", encoder.classes_)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our two approaches achieved the same results.  A Random Forest model is actually slightly better at feature selection than our greedy process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
